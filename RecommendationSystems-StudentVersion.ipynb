{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System rekomendujący na bazie Netflix Prize award\n",
    "\n",
    "1. Zacznijmy od obejrzenia wykładu [rozdział 9](http://www.mmds.org/)\n",
    "2. proszę ściągnac bazę netflixa o której była mowa w/w wykładzie [z kaggle](https://www.kaggle.com/netflix-inc/netflix-prize-data) (2GB) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaczniemy od wczytania danych, ponizszy listing wczytuje dane z jednego pliku i robi z nich trójkę (user, product, rating). Wykorzystamy do tego predefiniowany obiekt Rating z mlib.recommendation (prosze zwrócic uwagę że w tej konwencji nasz film będzie produktem)\n",
    "\n",
    "#### Zadanie 1:\n",
    "zmodyfikuj poniższy listing tak aby wczytywać wsystkie pięc plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File './RS/combined_data_1.txt' loaded!\n",
      "Finished! Processed lines: 24053764\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.mllib.recommendation import Rating\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# tutaj zaincjalizujemy klaster (na jednym komputerze) sparka\n",
    "# zmodyfikujemy nieco std ustawienia maszyny java zwiększając domyslne (bardzo małe) limity pamieci\n",
    "# local[*] oznacza że użyjemy wsystkich rdzeni - jeśli zabrankie nam ramu możemy zmniejszyć ilość tą ilość\n",
    "# polecam spoglądać do konsoli na http://localhost:4040/ aby monitorować zużycie zasobów\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName(\"recommendation\")\n",
    "conf = (conf.setMaster('local[*]')\n",
    "        .set('spark.executor.memory', '4G')\n",
    "        .set('spark.driver.memory', '20G')\n",
    "        .set('spark.driver.maxResultSize', '10G'))\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "#files = ['./RS/combined_data_1.txt',\n",
    "        #'./RS/combined_data_2.txt',\n",
    "        #'./RS/combined_data_3.txt',\n",
    "        #'./RS/combined_data_4.txt'] # Ufam, że użytkownik wprowadził nazwy plików, które istnieją...\n",
    "files = [ './RS/combined_data_1.txt' ]\n",
    "\n",
    "ratings = []\n",
    "for single_name in files:\n",
    "    f = open(single_name)\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip()\n",
    "        if line.endswith(':'):\n",
    "            movie_id = int(line[:-1])        \n",
    "        else:\n",
    "            user_id, rating, _ = line.split(',')\n",
    "            r = Rating(int(user_id), int(movie_id), int(rating))\n",
    "            ratings.append(r)\n",
    "    f.close()\n",
    "    print(\"File '\" + single_name + \"' loaded!\")\n",
    "\n",
    "print('Finished! Processed lines: ' + str(len(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#tutaj wczytamy identyfikatory filmów i ich tytuły\n",
    "\n",
    "f = open('./RS/movie_titles.csv', encoding = \"ISO-8859-1\")\n",
    "g = [l.strip().split(',') for l in f.readlines()]\n",
    "id2title = {int(a[0]):','.join(a[2:]) for a in g}\n",
    "f.close()\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "id2title\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! Elapsed time: 32.11 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# utworzmy z naszej listy ratingow zasob rdd (rozproszenie)\n",
    "start = time.time()\n",
    "ratings_rdd = sc.parallelize(ratings)\n",
    "end = time.time()\n",
    "print('Finished! Elapsed time: ' + str(round(end - start, 2)) + ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 2\n",
    "Przefiltruj ratings_rdd aby wziac pod uwage filmy ktory maja co najmniej 50 ocen\n",
    "tip: zrób napierw liste par (movie_id, Rating) i pogrupuj ją przy użyciu GroupByKey a nstępnie przefiltruj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_pairs = ratings_rdd.map(lambda r: (r.product, r))\n",
    "rg = ratings_pairs.groupByKey() # ???\n",
    "\n",
    "# ???\n",
    "ratings_filtered = rg.filter(lambda r: len(r[1]) >= 50).collect() # ???\n",
    "\n",
    "\n",
    "# zasob rdd na przefiltrowanym obiekcie\n",
    "ratings_filtered = sc.parallelize(ratings_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 - finished!\n",
      "Stage 2 - finished!\n",
      "Stage 3 - finished!\n",
      "Stage 4 - finished!\n",
      "Stage 5 - finished!\n",
      "Stage 6 - finished!\n",
      "Finished! Elapsed time: 161.56 seconds.\n"
     ]
    }
   ],
   "source": [
    "# TROCHĘ INNYM SPOSOBEM - na około (zmiana na DataFrame po to by korzystać z SQL Queries)\n",
    "import pyspark.sql.functions as ps_functions\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "data = SQLContext(sc)\n",
    "print('Stage 1 - finished!')\n",
    "\n",
    "all_ratings = data.createDataFrame(ratings_rdd)\n",
    "print('Stage 2 - finished!')\n",
    "\n",
    "fragment = Window.partitionBy('product')\n",
    "print('Stage 3 - finished!')\n",
    "\n",
    "query = all_ratings.select('user', 'product', 'rating', ps_functions.count('product').over(fragment).alias(\"ratings_count\"))\n",
    "print('Stage 4 - finished!')\n",
    "\n",
    "marker = query.filter(\"ratings_count >= 50\").select('user','product','rating')\n",
    "print('Stage 5 - finished!')\n",
    "\n",
    "ratings = sc.parallelize(marker.collect())\n",
    "print('Stage 6 - finished!')\n",
    "\n",
    "end = time.time()\n",
    "print('Finished! Elapsed time: ' + str(round(end - start, 2)) + ' seconds.')\n",
    "# TROCHĘ INNYM SPOSOBEM - na około (zmiana na DataFrame po to by korzystać z SQL Queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokonamy teraz faktoryzacji macierzy, nasej utility Matrix (zasób RDD ratings_filtered jest własnie taką macierzą) przy użyciu aproksymacji algorytmu spadku gradientowego\n",
    "![alt](https://edersoncorbari.github.io/assets/images/blog/als-matrix-rec-calc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! Elapsed time: 81.59 seconds.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import time\n",
    "\n",
    "rank = 10\n",
    "numIterations = 10\n",
    "\n",
    "start = time.time()\n",
    "model = ALS.train(ratings, rank, numIterations)\n",
    "end = time.time()\n",
    "print('Finished! Elapsed time: ' + str(round(end - start, 2)) + ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zrzucilismy uzytkowników i filmy na nowy wymiar o wielkości 10. Możemy wprost poprosić o te macierze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users  = model.userFeatures()\n",
    "movies = model.productFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gęsta ale 'wąska' macierz movies zmieści się nam już bezproblemowo w RAM, a zatem zróbmy z niej po prostu macierz numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "movies_mtx = np.array(movies.map(lambda rv:rv[1]).collect())\n",
    "movie2row_number = movies.map(lambda rv:rv[0]).collect() #movie id to row number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zróbmy prosty ekesperyment, zobaczmy czy jakie filmy są 'podobne' do 'Władcy pierścieni'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Lord of the Rings\n",
      "[-0.40519634  0.3050507  -0.53807741 -0.01964168  0.31152999 -0.15673974\n",
      " -0.26772276  0.13672216 -0.47071424  0.00552696]\n"
     ]
    }
   ],
   "source": [
    "id2title[1757] # 'The Lord of the Rings'\n",
    "\n",
    "lotr_idx = movie2row_number.index(1757)\n",
    "lotr_vector = movies_mtx[lotr_idx]\n",
    "print('Title: ' + id2title[1757])\n",
    "print(lotr_vector) #to jest wladca pierscienie rzutowany na latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: [1561 3816 4170 1279 2782  142 2501 2413 4126  824]\n",
      "Movie title using ID 1561: The Lord of the Rings\n",
      "Movie title using ID 3816: Alien: Resurrection: Collector's Edition\n",
      "Movie title using ID 4170: Campfire Stories\n",
      "Movie title using ID 1279: Firestarter\n",
      "Movie title using ID 2782: The Return of the King\n",
      "Movie title using ID 142: The Masque of the Red Death / The Premature Burial\n",
      "Movie title using ID 2501: Silver Bullet\n",
      "Movie title using ID 2413: Hellbound: Hellraiser II\n",
      "Movie title using ID 4126: Lord of Illusions\n",
      "Movie title using ID 824: Taste the Blood of Dracula\n"
     ]
    }
   ],
   "source": [
    "# obliczmy macierz odleglosci \n",
    "from scipy.spatial import distance\n",
    "\n",
    "ds = distance.cdist([lotr_vector], movies_mtx, 'cosine')[0]\n",
    "dist = ds.argsort()[:10] # 10 - liczba filmów\n",
    "\n",
    "print('Distance: ' + str(dist))\n",
    "\n",
    "for i in dist:\n",
    "    print('Movie title using ID ' + str(i) + ': ' + id2title[movie2row_number[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance value: 0.0 refers movie: The Lord of the Rings\n",
      "Distance value: 0.06194802950162004 refers movie: Alien: Resurrection: Collector's Edition\n",
      "Distance value: 0.06650902880989118 refers movie: Campfire Stories\n",
      "Distance value: 0.07866967773630595 refers movie: Firestarter\n",
      "Distance value: 0.08017573924912091 refers movie: The Return of the King\n",
      "Distance value: 0.08197936900477432 refers movie: The Masque of the Red Death / The Premature Burial\n",
      "Distance value: 0.08375122220501197 refers movie: Silver Bullet\n",
      "Distance value: 0.08576027762557836 refers movie: Hellbound: Hellraiser II\n",
      "Distance value: 0.0861341589001966 refers movie: Lord of Illusions\n",
      "Distance value: 0.08635267782427059 refers movie: Taste the Blood of Dracula\n"
     ]
    }
   ],
   "source": [
    "for i in dist:\n",
    "    print('Distance value: ' + str(ds[i]) + \" refers movie: \" + id2title[movie2row_number[i]])\n",
    "\n",
    "# print(str(ds[2018]) + ': ' + id2title[movie2row_number[2018]])\n",
    "# print(str(ds[928]) + ': ' + id2title[movie2row_number[928]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odległosć 0.0 to oczywiscie ten sam obiekt a zatem interesuje nas drugi w kolejności wpis. I cóż za niespodzianka? ludzie którzy ocenili wysoko Władce pierścieni ocenili również wysokos Powrót Króla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na ile cech powinniśmy faktoryzować Utility Matrix? \n",
    "\n",
    "#### Zadanie 3\n",
    "Dobierz paramter rank (ilość cech) dla obiektu ALS dzieląc zbiór ratings_filtered na 80% vs 20% (treningowy i testowy, tak jak na wykłdzie). Następnie wykorzystać metodę ALS.recommendProductsForUsers aby polecić filmy i zweryfikuj ile filmów udało Ci sie prawidłowo polecić ze zbioru testowego. Odpowiednio modyfikuj parametr rank aby otrzymać względnie wysoki wynik rekomendacji jednocześnie utrymując w miare wąskie macierze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File './RS/combined_data_1.txt' loaded!\n",
      "Loading finished! Processed lines: 24053764\n",
      "IDs and titles loaded!!\n",
      "RDD resource created! Elapsed time: 31.39 seconds.\n"
     ]
    }
   ],
   "source": [
    "#files = ['./RS/combined_data_1.txt',\n",
    "        #'./RS/combined_data_2.txt',\n",
    "        #'./RS/combined_data_3.txt',\n",
    "        #'./RS/combined_data_4.txt'] # Ufam, że użytkownik wprowadził nazwy plików, które istnieją...\n",
    "files = [ './RS/combined_data_1.txt' ]\n",
    "\n",
    "ratings = []\n",
    "for single_name in files:\n",
    "    f = open(single_name)\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip()\n",
    "        if line.endswith(':'):\n",
    "            movie_id = int(line[:-1])        \n",
    "        else:\n",
    "            user_id, rating, _ = line.split(',')\n",
    "            r = Rating(int(user_id), int(movie_id), int(rating))\n",
    "            ratings.append(r)\n",
    "    f.close()\n",
    "    print(\"File '\" + single_name + \"' loaded!\")\n",
    "\n",
    "print('Loading finished! Processed lines: ' + str(len(ratings)))\n",
    "\n",
    "f = open('./RS/movie_titles.csv', encoding = \"ISO-8859-1\")\n",
    "g = [l.strip().split(',') for l in f.readlines()]\n",
    "id2title = {int(a[0]):','.join(a[2:]) for a in g}\n",
    "f.close()\n",
    "print('IDs and titles loaded!!')\n",
    "\n",
    "start = time.time()\n",
    "ratings_rdd = sc.parallelize(ratings)\n",
    "end = time.time()\n",
    "print('RDD resource created! Elapsed time: ' + str(round(end - start, 2)) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 - finished!\n",
      "Stage 2 - finished!\n",
      "Stage 3 - finished!\n",
      "Stage 4 - finished!\n",
      "Stage 5 - finished!\n",
      "Stage 6 - finished!\n",
      "Finished! Elapsed time: 191.64 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as ps_functions\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "data = SQLContext(sc)\n",
    "print('Stage 1 - finished!')\n",
    "\n",
    "all_ratings = data.createDataFrame(ratings_rdd) # Tu zawsze pojawia się error przy pierwszym uruchomieniu. Drugie uruchomienie już go nie wywołuje\n",
    "print('Stage 2 - finished!')\n",
    "\n",
    "fragment = Window.partitionBy('product')\n",
    "print('Stage 3 - finished!')\n",
    "\n",
    "query = all_ratings.select('user', 'product', 'rating', ps_functions.count('product').over(fragment).alias(\"ratings_count\"))\n",
    "print('Stage 4 - finished!')\n",
    "\n",
    "marker = query.filter(\"ratings_count >= 50\").select('user','product','rating')\n",
    "print('Stage 5 - finished!')\n",
    "\n",
    "ratings = sc.parallelize(marker.collect())\n",
    "print('Stage 6 - finished!')\n",
    "\n",
    "end = time.time()\n",
    "print('Finished! Elapsed time: ' + str(round(end - start, 2)) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "############################################################\n",
    "\n",
    "train, valid, test = ratings.randomSplit([6,2,2], seed=0)\n",
    "emptyTest = test.map(lambda r: (r[0], r[1]))\n",
    "emptyValid = valid.map(lambda r: (r[0], r[1]))\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for rank: 1/20. Elapsed time: 171.41 seconds.\n",
      "Training completed for rank: 2/20. Elapsed time: 170.07 seconds.\n",
      "Training completed for rank: 3/20. Elapsed time: 176.82 seconds.\n",
      "Training completed for rank: 4/20. Elapsed time: 167.7 seconds.\n",
      "Training completed for rank: 5/20. Elapsed time: 171.93 seconds.\n",
      "Training completed for rank: 6/20. Elapsed time: 181.9 seconds.\n",
      "Rank 7 has encountered a problem! Data restored.\n",
      "Training completed for rank: 8/20. Elapsed time: 204.33 seconds.\n",
      "Training completed for rank: 9/20. Elapsed time: 196.27 seconds.\n",
      "Training completed for rank: 10/20. Elapsed time: 199.04 seconds.\n",
      "Training completed for rank: 11/20. Elapsed time: 212.8 seconds.\n",
      "Rank 12 has encountered a problem! Data restored.\n",
      "Training completed for rank: 13/20. Elapsed time: 208.94 seconds.\n",
      "Training completed for rank: 14/20. Elapsed time: 230.77 seconds.\n",
      "Training completed for rank: 15/20. Elapsed time: 221.64 seconds.\n",
      "Rank 16 has encountered a problem! Data restored.\n",
      "Training completed for rank: 17/20. Elapsed time: 248.2 seconds.\n",
      "Training completed for rank: 18/20. Elapsed time: 225.61 seconds.\n",
      "Training completed for rank: 19/20. Elapsed time: 249.17 seconds.\n",
      "Training completed for rank: 20/20. Elapsed time: 237.23 seconds.\n",
      "The best rank 20\n"
     ]
    }
   ],
   "source": [
    "ranks = range(1, 21)\n",
    "\n",
    "errorsList = []\n",
    "models = []\n",
    "for i in range(len(ranks)):\n",
    "    errorsList.append(0)\n",
    "ind = 0\n",
    "\n",
    "remembered_error = float('inf')\n",
    "the_best_rank = -1\n",
    "for rank in ranks:\n",
    "    try: # POJAWIA SIĘ PROBLEM Z TCP OBSŁUGIWANYM PRZEZ JAVĘ - dlatego try-except\n",
    "        start = time.time()\n",
    "        # Jeżeli wystąpi `error` to w bloku poniżej\n",
    "        model = ALS.train(train, rank, seed=5, iterations=20, lambda_=0.1)\n",
    "        pred = model.predictAll(emptyValid).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "        rates = valid.map(lambda r: ((r[0], r[1]), r[2])).join(pred)\n",
    "        newError = math.sqrt(rates.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "        # Jeżeli wystąpi `error` to w bloku powyżej\n",
    "        errorsList[ind] = newError\n",
    "        ind += 1\n",
    "        if newError < remembered_error:\n",
    "            remembered_error = newError\n",
    "            the_best_rank = rank\n",
    "        end = time.time()\n",
    "        # Zapamiętaj ostatni poprawnie wykonany zbiór zmiennych (poniżej)\n",
    "        last_correct_model = model\n",
    "        last_correct_pred = pred\n",
    "        last_correct_rates = rates\n",
    "        last_correct_newError = newError\n",
    "        # Zapamiętaj ostatni poprawnie wykonany zbiór zmiennych (powyżej)\n",
    "        print('Training completed for rank: ' + str(rank) + '/' + str(len(ranks)) + '. Elapsed time: ' + str(round(end - start, 2)) + ' seconds.')\n",
    "    except:\n",
    "        # W razie błędu odzyskaj ostatni poprawnie wykonany zbiór zmiennych (poniżej)\n",
    "        model = last_correct_model\n",
    "        pred = last_correct_pred\n",
    "        rates = last_correct_rates\n",
    "        newError = last_correct_newError\n",
    "        # W razie błędu odzyskaj ostatni poprawnie wykonany zbiór zmiennych (powyżej)\n",
    "        print('Rank ' + str(rank) + ' has encountered a problem! Data restored.')\n",
    "print(\"The best rank %s\" % the_best_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test completed for rank: 20 Elapsed time: 196.59 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1374416,\n",
       " (Rating(user=1374416, product=2700, rating=4.866043521149377),\n",
       "  Rating(user=1374416, product=3033, rating=4.721042942324603),\n",
       "  Rating(user=1374416, product=1230, rating=4.708888030404897),\n",
       "  Rating(user=1374416, product=2102, rating=4.6854508074529715),\n",
       "  Rating(user=1374416, product=3456, rating=4.6836380275702485),\n",
       "  Rating(user=1374416, product=223, rating=4.674958529953608),\n",
       "  Rating(user=1374416, product=3444, rating=4.671594230892056),\n",
       "  Rating(user=1374416, product=724, rating=4.635454454397707),\n",
       "  Rating(user=1374416, product=1418, rating=4.603810422278698),\n",
       "  Rating(user=1374416, product=2172, rating=4.603664821979537)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = ratings.randomSplit([8,2], seed=0)\n",
    "emptyTest = test.map(lambda r: (r[0], r[1]))\n",
    "\n",
    "############################################################\n",
    "\n",
    "start = time.time()\n",
    "model = ALS.train(train, the_best_rank, seed=5, iterations=20, lambda_=0.1)\n",
    "pred = model.predictAll(emptyTest).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates = test.map(lambda r: ((r[0], r[1]), r[2])).join(pred)\n",
    "end = time.time()\n",
    "print('Test completed for rank: ' + str(the_best_rank) + ' Elapsed time: ' + str(round(end - start, 2)) + ' seconds.')\n",
    "\n",
    "############################################################\n",
    "\n",
    "products = model.recommendProductsForUsers(10)\n",
    "products.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies: \n",
      "\"Fight Club: Bonus Material\" for value 4.866043521149377\n",
      "\"Thomas & Sarah\" for value 4.721042942324603\n",
      "\"The Element of Crime\" for value 4.708888030404897\n",
      "\"Niea 7\" for value 4.6854508074529715\n",
      "\"Tuck Everlasting\" for value 4.6836380275702485\n",
      "\"Cinderella II\" for value 4.674958529953608\n",
      "\"Creepshow\" for value 4.671594230892056\n",
      "\"Scratch\" for value 4.635454454397707\n",
      "\"Black Orpheus\" for value 4.603810422278698\n",
      "\"King Cobra\" for value 4.603664821979537\n",
      "\n",
      "Title of watched movie: The Lord of the Rings\n",
      "Vector of watched movie:\n",
      "[-0.40519634  0.3050507  -0.53807741 -0.01964168  0.31152999 -0.15673974\n",
      " -0.26772276  0.13672216 -0.47071424  0.00552696]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "productions = model.productFeatures()\n",
    "productions_matrix = np.array(movies.map(lambda rv:rv[1]).collect())\n",
    "m2rn = productions.map(lambda rv:rv[0]).collect()\n",
    "\n",
    "############################################################\n",
    "\n",
    "print('Recommended movies: ')\n",
    "for i in enumerate(products.first()[1]):\n",
    "    product_index = i[1][1]\n",
    "    print(\"\\\"\" + id2title[m2rn.index(product_index)] + \"\\\" for value %s\" % i[1][2])\n",
    "\n",
    "id2title[1757]\n",
    "lotr_idx = m2rn.index(1757)\n",
    "lotr_vector = productions_matrix[lotr_idx]\n",
    "\n",
    "############################################################\n",
    "\n",
    "print('\\nTitle of watched movie: ' + id2title[1757])\n",
    "print('Vector of watched movie:')\n",
    "print(lotr_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 4\n",
    "Zrób program \"co obejrzeć dziś wieczorem\".\n",
    "Program powinien pokazaywać 5 tytułow, uzytkownik wskazuje jeden lub kilka z nich i system pokazuje kolejne rekomendacje. Każda kolejna rekomendacja powinna wskazywać coraz lepsze rekomendacje. \n",
    "\n",
    "problem można rozwiazać na kilka sposób. Można pogrupować przestrzeń filmów (macierz P.T) i pokazywać z różnych np. centroidy klastrów (które będą reprezentować gatunki filmów (prawdopodobnie) ). \n",
    "\n",
    "każde kolejne wybranie filmu będzie wymagało stworzenie nowego sztuznego użytkownika z ratingiem. W każdej iteracji takiego użytkownika należy rzucic na macierz Q (czyli na latentną macierz użytkownika). Przypatrz się dokładnie sposobowi mnożenia na obrazku powyżej i zastanów się jak otrzymać takiego użytkownika w przestrzeni cech?). Przypominam że macierz P.T jest nieodracalna ale można wykorzystać pseudo odwrotnosć."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
