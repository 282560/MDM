{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System rekomendujący na bazie Netflix Prize award\n",
    "\n",
    "1. Zacznijmy od obejrzenia wykładu [rozdział 9](http://www.mmds.org/)\n",
    "2. proszę ściągnac bazę netflixa o której była mowa w/w wykładzie [z kaggle](https://www.kaggle.com/netflix-inc/netflix-prize-data) (2GB) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaczniemy od wczytania danych, ponizszy listing wczytuje dane z jednego pliku i robi z nich trójkę (user, product, rating). Wykorzystamy do tego predefiniowany obiekt Rating z mlib.recommendation (prosze zwrócic uwagę że w tej konwencji nasz film będzie produktem)\n",
    "\n",
    "#### Zadanie 1:\n",
    "zmodyfikuj poniższy listing tak aby wczytywać wsystkie pięc plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File './RS/combined_data_1.txt' loaded!\n",
      "File './RS/combined_data_2.txt' loaded!\n",
      "File './RS/combined_data_3.txt' loaded!\n",
      "File './RS/combined_data_4.txt' loaded!\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.mllib.recommendation import Rating\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# tutaj zaincjalizujemy klaster (na jednym komputerze) sparka\n",
    "# zmodyfikujemy nieco std ustawienia maszyny java zwiększając domyslne (bardzo małe) limity pamieci\n",
    "# local[*] oznacza że użyjemy wsystkich rdzeni - jeśli zabrankie nam ramu możemy zmniejszyć ilość tą ilość\n",
    "# polecam spoglądać do konsoli na http://localhost:4040/ aby monitorować zużycie zasobów\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName(\"recommendation\")\n",
    "conf = (conf.setMaster('local[*]')\n",
    "        .set('spark.executor.memory', '4G')\n",
    "        .set('spark.driver.memory', '20G')\n",
    "        .set('spark.driver.maxResultSize', '10G'))\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "files = ['./RS/combined_data_1.txt',\n",
    "        './RS/combined_data_2.txt',\n",
    "        './RS/combined_data_3.txt',\n",
    "        './RS/combined_data_4.txt'] # Ufam, że użytkownik wprowadził nazwy plików, które istnieją...\n",
    "\n",
    "ratings = []\n",
    "for single_name in files:\n",
    "    f = open(single_name)\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip()\n",
    "        if line.endswith(':'):\n",
    "            movie_id = int(line[:-1])        \n",
    "        else:\n",
    "            user_id, rating, _ = line.split(',')\n",
    "            r = Rating(int(user_id), int(movie_id), int(rating))\n",
    "            ratings.append(r)\n",
    "    f.close()\n",
    "    print(\"File '\" + single_name + \"' loaded!\")\n",
    "\n",
    "print('Finished! Processed lines: ' + str(len(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#tutaj wczytamy identyfikatory filmów i ich tytuły\n",
    "\n",
    "f = open('./RS/movie_titles.csv', encoding = \"ISO-8859-1\")\n",
    "g = [l.strip().split(',') for l in f.readlines()]\n",
    "id2title = {int(a[0]):','.join(a[2:]) for a in g}\n",
    "f.close()\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "id2title\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# utworzmy z naszej listy ratingow zasob rdd (rozproszenie)\n",
    "ratings_rdd = sc.parallelize(ratings)\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 2\n",
    "Przefiltruj ratings_rdd aby wziac pod uwage filmy ktory maja co najmniej 50 ocen\n",
    "tip: zrób napierw liste par (movie_id, Rating) i pogrupuj ją przy użyciu GroupByKey a nstępnie przefiltruj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[1] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "ratings_pairs = ratings_rdd.map(lambda r: (r.product, r))\n",
    "rg = ratings_keyed.groupByKey().  ????\n",
    "\n",
    "??????\n",
    "ratings_filtered = ???????.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zasob rdd na przefiltrowanym obiekcie\n",
    "ratings_filtered = sc.parallelize(ratings_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokonamy teraz faktoryzacji macierzy, nasej utility Matrix (zasób RDD ratings_filtered jest własnie taką macierzą) przy użyciu aproksymacji algorytmu spadku gradientowego\n",
    "![alt](https://edersoncorbari.github.io/assets/images/blog/als-matrix-rec-calc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 10\n",
    "numIterations = 10\n",
    "model = ALS.train(ratings_filtered, rank, numIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zrzucilismy uzytkowników i filmy na nowy wymiar o wielkości 10. Możemy wprost poprosić o te macierze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "users  = model.userFeatures()\n",
    "movies = model.productFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gęsta ale 'wąska' macierz movies zmieści się nam już bezproblemowo w RAM, a zatem zróbmy z niej po prostu macierz numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_mtx = np.array(movies.map(lambda rv:rv[1]).collect())\n",
    "movie2row_number = movies.map(lambda rv:rv[0]).collect() #movie id to row number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zróbmy prosty ekesperyment, zobaczmy czy jakie filmy są 'podobne' do 'Władcy pierścieni'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29456642, -0.24367087, -0.11916542, -0.70450312, -0.52015817,\n",
       "        0.22564895,  0.08156089,  0.19098088, -0.75671792,  0.3677029 ])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2title[1757] # 'The Lord of the Rings'\n",
    "\n",
    "lotr_idx = movie2row_number.index(1757)\n",
    "lotr_vector = movies_mtx[lotr_idx]\n",
    "lotr_vector #to jest wladca pierscienie rzutowany na latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018,  928, 3172, 3063,  605,  206, 1237, 3116,  734, 1296])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obliczmy macierz odleglosci \n",
    "from scipy.spatial import distance\n",
    "ds = distance.cdist([lotr_vector], m_l, 'cosine')[0]\n",
    "ds.argsort()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 : The Lord of the Rings\n",
      "0.05174156358429072 : The Return of the King\n"
     ]
    }
   ],
   "source": [
    "print(ds[2018], ':', id2title[movie2row_number[2018]])\n",
    "print(ds[928], ':', id2title[movie2row_number[928]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odległosć 0.0 to oczywiscie ten sam obiekt a zatem interesuje nas drugi w kolejności wpis. I cóż za niespodzianka? ludzie którzy ocenili wysoko Władce pierścieni ocenili również wysokos Powrót Króla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na ile cech powinniśmy faktoryzować Utility Matrix? \n",
    "\n",
    "#### Zadanie 3\n",
    "Dobierz paramter rank (ilość cech) dla obiektu ALS dzieląc zbiór ratings_filtered na 80% vs 20% (treningowy i testowy, tak jak na wykłdzie). Następnie wykorzystać metodę ALS.recommendProductsForUsers aby polecić filmy i zweryfikuj ile filmów udało Ci sie prawidłowo polecić ze zbioru testowego. Odpowiednio modyfikuj parametr rank aby otrzymać względnie wysoki wynik rekomendacji jednocześnie utrymując w miare wąskie macierze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 4\n",
    "Zrób program \"co obejrzeć dziś wieczorem\".\n",
    "Program powinien pokazaywać 5 tytułow, uzytkownik wskazuje jeden lub kilka z nich i system pokazuje kolejne rekomendacje. Każda kolejna rekomendacja powinna wskazywać coraz lepsze rekomendacje. \n",
    "\n",
    "problem można rozwiazać na kilka sposób. Można pogrupować przestrzeń filmów (macierz P.T) i pokazywać z różnych np. centroidy klastrów (które będą reprezentować gatunki filmów (prawdopodobnie) ). \n",
    "\n",
    "każde kolejne wybranie filmu będzie wymagało stworzenie nowego sztuznego użytkownika z ratingiem. W każdej iteracji takiego użytkownika należy rzucic na macierz Q (czyli na latentną macierz użytkownika). Przypatrz się dokładnie sposobowi mnożenia na obrazku powyżej i zastanów się jak otrzymać takiego użytkownika w przestrzeni cech?). Przypominam że macierz P.T jest nieodracalna ale można wykorzystać pseudo odwrotnosć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
